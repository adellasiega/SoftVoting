# Preprocessing

## Scaling
```{r}
# Load the data
data <- read.csv("data/train.csv", header = TRUE, sep = ",")
```

```{r}
# Perform Min-Max Normalization on each column
minmax_norm <- function(x) {
  return ((x - min(x)) / (max(x) - min(x)))
}

data <- as.data.frame(lapply(data, minmax_norm))
```

## Balancing target variable on the training set

```{r}
# Perform ROSE oversampling
library(ROSE)
n_0 <- nrow(data[data["CARAVAN"] == 0, ])
p <- 1
rose_data <- ovun.sample(CARAVAN ~ .,
                         data = data,
                         method = "over",
                         N = n_0 + round(p * n_0))$data
#Save the data
write.csv(rose_data, "data/train_rose.csv", row.names = FALSE)
```
For the ROSE oversampling, the number of samples in the minority class is set to
be equal to the number of samples in the majority class.

```{r}
table(rose_data$CARAVAN)
```

```{r}
summary(rose_data)
```

```{r}
#Performing the same normalization on the test set
test_data <- read.csv("data/test.csv", header = TRUE, sep = ",")
test_data <- as.data.frame(lapply(test_data, minmax_norm))
write.csv(test_data, "data/test.csv", row.names = FALSE)
```






