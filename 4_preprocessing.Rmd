# Preprocessing

```{r}
# Load the data
train <- read.csv("data/train_raw.csv", header = TRUE, sep = ",")
test <- read.csv("data/test_raw.csv", header = TRUE, sep = ",")
```

## Variable Selection
Remove the redundant variables that we found during the correlation analysis.
```{r}
library(caret)
corr_matrix <- cor(train)
multicorr_columns <- c()
n_col <- ncol(cor_matrix) - 1 #exclude the target variable
corr_threshold <- 0.7

for (i in seq_len(n_col - 1)) {
  for (j in seq(i + 1, n_col)) {
    if (abs(cor_matrix[i, j]) > corr_threshold) {
      print(paste(colnames(cor_matrix)[i], colnames(cor_matrix)[j],
                  cor_matrix[i, j]))
      multicorr_columns <- c(multicorr_columns, colnames(cor_matrix)[j])
    }
  }
}

print(multicorr_columns)
```

Remove the redundant (multicollinear) variables
```{r}
train <- train[, !colnames(train) %in% multicorr_columns]
test <- test[, !colnames(test) %in% multicorr_columns]
```

The columns left are
```{r}
colnames(train)
```

## One Hot Encoding
The variables MOSTYPE and MOSHOOFD need to be one hot encoded. Actually, the variable MOSHOOFD has been remove during correlation analysis since it is a generalization of MOSTYPE.
```{r}
# One hot encoding function
one_hot <- function(data, variable) {
  library(caret)
  # Convert the variable to factor
  data[[variable]] <- as.factor(data[[variable]])
  # Perform one hot encoding
  dummy <- dummyVars(" ~ .", data = data)
  data <- data.frame(predict(dummy, newdata = data))
  return(data)
}

train <- one_hot(train, "MOSTYPE")
test <- one_hot(test, "MOSTYPE")
```

```{r}
str(train)
```

```{r}
str(test)
```


## Scaling

Let's perform Min-Max Normalization on each variale. Note that each variable has a different domain, since it could belong to a different domain, so we need to specify the normalization for each variable.
The target variable CARAVAN is not normalized, since it is a binary variable.

```{r}
minmax <- function(data) {
  
  # Domain MAANTHUI:  [1,10]
  if ("MAANTHUI" %in% colnames(data)) {
    data$MAANTHUI <- (data$MAANTHUI - 1) / (10 - 1)
  }
  # Domain MGEMOMV and MGEMLEEF:  [1,6]
  if ("MGEMOMV" %in% colnames(data)) {
    data$MGEMOMV <- (data$MGEMOMV - 1) / (6 - 1)
  }
  if ("MGEMLEEF" %in% colnames(data)) {
    data$MMGEMLEEF <- (data$MGEMLEEF - 1) / (6 - 1)
  }

  # All the other variables have domain [0, 9]
  for (i in colnames(data)) {
    if (i != "CARAVAN" &&
        i != "MAANTHUI" &&
        i != "MGEMOMV" &&
        i != "MGEMLEEF") {
      data[[i]] <- (data[[i]] - 0) / (9 - 0)
    }
  }
  return(data)
}

train <- minmax(train)
test <- minmax(test)
#save test data
write.csv(test, "data/test.csv", row.names = FALSE)
```
```{r}
str(train)
```

```{r}
str(test)
```

## Balancing target variable on the training set

```{r}
# Perform ROSE oversampling
library(ROSE)
n_0 <- nrow(train[train["CARAVAN"] == 0, ])
print(n_0)
rose <- ovun.sample(CARAVAN ~ .,
                    data = train,
                    method = "over",
                    N = 2 * n_0)
#Save the data
write.csv(rose$data, "data/train_rose.csv", row.names = FALSE)
```
The CARAVAN variable in the train set is now perfectly balanced, as all things should be.

```{r}
table(rose_data$CARAVAN)
```

```{r}
str(rose_data)
```