# Bagging

```{r, echo=FALSE}
library(dplyr)
library(purrr)
# library(caret)
library(MLmetrics)
```

Load the train data set on which ROSE was applied
```{r}
train_rose <- read.csv("data/train_rose.csv")
test <- read.csv("data/test.csv")

SEED <- 42
set.seed(SEED)
suppressWarnings(sqrt(-1))  # Suppresses the warning generated by taking the square root of a negative number

train_perc = 0.8
train_size = round(nrow(train_rose) * train_perc,0)
train_index = sample(1:nrow(train_rose), train_size)
train = train_rose[train_index,]
val = train_rose[-train_index,]
```



Generate m bootstrap samples from the training set
```{r}
m = 20
perc = 0.8
n = round(nrow(train) * perc, 0)
bootstrap_samples <- list()
for (i in 1:m) {
  bootstrap_samples[[i]] <- train[sample(1:n, n, replace = TRUE), ]
}
```

```{r}
balanced_accuracy <- function(true_labels, predicted_labels) {
  # Ensure that the inputs are factors and have the same levels
  true_labels <- factor(true_labels)
  predicted_labels <- factor(predicted_labels, levels = levels(true_labels))
  
  # Calculate confusion matrix
  cm <- table(True = true_labels, Predicted = predicted_labels)
  
  # Calculate sensitivity (recall) for each class
  sensitivity <- diag(prop.table(cm, 1))
  
  # Calculate balanced accuracy
  balanced_accuracy <- mean(sensitivity)
  
  return(balanced_accuracy)
}
```

## Hard Voting

```{r, echo=FALSE}
y_pred_val <- matrix(0, nrow = nrow(val), ncol = m)
y_pred_test <- matrix(0, nrow = nrow(test), ncol = m)

for(i in 1:m) {
  model <- glm(formula = CARAVAN ~ ., data = bootstrap_samples[[i]], family = "binomial")
  y_pred_val[,i] <- predict(model, newdata = val)
  y_pred_test[,i] <- predict(model, newdata = test)
}

y_pred_val <- ifelse(rowMeans(y_pred_val) > 0.5, 1, 0)
y_pred_test <- ifelse(rowMeans(y_pred_test) > 0.5, 1, 0)
```

```{r}
acc_val_hard <- mean(y_pred_val == val$CARAVAN)
acc_test_hard <- mean(y_pred_test == test$CARAVAN)
acc_val_hard <- round(acc_val_hard*100, 2)
acc_test_hard <- round(acc_test_hard*100, 2)

bacc_val_hard <- balanced_accuracy(val$CARAVAN, y_pred_val)
bacc_test_hard <- balanced_accuracy(test$CARAVAN, y_pred_test)
bacc_val_hard <- round(bacc_val_hard*100, 2)
bacc_test_hard <- round(bacc_test_hard*100, 2)

f1_val_hard <- F1_Score(val$CARAVAN, y_pred_val)
f1_test_hard <- F1_Score(test$CARAVAN, y_pred_test)
f1_val_hard <- round(f1_val_hard*100, 2)
f1_test_hard <- round(f1_test_hard*100, 2)

print(paste("Validation Accuracy: ", acc_val_hard))
print(paste("Test Accuracy: ", acc_test_hard))
print(paste("Validation Balanced Accuracy: ", bacc_val_hard))
print(paste("Test Balanced Accuracy: ", bacc_test_hard))
print(paste("Validation F1 Score: ", f1_val_hard))
print(paste("Test F1 Score: ", f1_test_hard))

```


## Soft Voting

```{r, echo=FALSE}
y_pred_val <- matrix(0, nrow = nrow(val), ncol = m)
y_pred_test <- matrix(0, nrow = nrow(test), ncol = m)

for(i in 1:m) {
  model <- glm(formula = CARAVAN ~ ., data = bootstrap_samples[[i]], family = "binomial")
  y_pred_val[,i] <- predict(model, newdata = val, type = "response")
  y_pred_test[,i] <- predict(model, newdata = test, type = "response")
}

y_pred_val <- ifelse(rowMeans(y_pred_val) > 0.5, 1, 0)
y_pred_test <- ifelse(rowMeans(y_pred_test) > 0.5, 1, 0)
```

```{r}
acc_val_soft <- mean(y_pred_val == val$CARAVAN)
acc_test_soft <- mean(y_pred_test == test$CARAVAN)
acc_val_soft <- round(acc_val_soft*100, 2)
acc_test_soft <- round(acc_test_soft*100, 2)

bacc_val_soft <- balanced_accuracy(val$CARAVAN, y_pred_val)
bacc_test_soft <- balanced_accuracy(test$CARAVAN, y_pred_test)
bacc_val_soft <- round(bacc_val_soft*100, 2)
bacc_test_soft <- round(bacc_test_soft*100, 2)

f1_val_soft <- F1_Score(val$CARAVAN, y_pred_val)
f1_test_soft <- F1_Score(test$CARAVAN, y_pred_test)
f1_val_soft <- round(f1_val_soft*100, 2)
f1_test_soft <- round(f1_test_soft*100, 2)

print(paste("Validation Accuracy: ", acc_val_soft))
print(paste("Test Accuracy: ", acc_test_soft))
print(paste("Validation Balanced Accuracy: ", bacc_val_soft))
print(paste("Test Balanced Accuracy: ", bacc_test_soft))
print(paste("Validation F1 Score: ", f1_val_soft))
print(paste("Test F1 Score: ", f1_test_soft))

```





