# Bagging

```{r, echo=FALSE}
library(dplyr)
library(purrr)
# library(caret)
```

Load the train data set on which ROSE was applied
```{r}
train_rose <- read.csv("data/train_rose.csv")
test <- read.csv("data/test.csv")

SEED <- 42
set.seed(SEED)
suppressWarnings(sqrt(-1))  # Suppresses the warning generated by taking the square root of a negative number

train_perc = 0.8
train_size = round(nrow(train_rose) * train_perc,0)
train_index = sample(1:nrow(train_rose), train_size)
train = train_rose[train_index,]
val = train_rose[-train_index,]
```



Generate m bootstrap samples from the training set
```{r}
m = 10
perc = 1
n = round(nrow(train) * perc, 0)
bootstrap_samples <- list()
for (i in 1:m) {
  bootstrap_samples[[i]] <- train[sample(1:n, n, replace = TRUE), ]
}
```


## Hard Voting

80-20 split for train and validation

```{r}
y_pred_val <- matrix(0, nrow = nrow(val), ncol = m)
y_pred_test <- matrix(0, nrow = nrow(test), ncol = m)

for(i in 1:m) {
  model <- glm(formula = CARAVAN ~ ., data = bootstrap_samples[[i]], family = "binomial")
  y_pred_val[,i] <- predict(model, newdata = val)
  y_pred_test[,i] <- predict(model, newdata = test)
}

y_pred_val <- ifelse(rowMeans(y_pred_val) > 0.5, 1, 0)
y_pred_test <- ifelse(rowMeans(y_pred_test) > 0.5, 1, 0)
```

```{r}
acc_val_hard <- mean(y_pred_val == val$CARAVAN)
acc_test_hard <- mean(y_pred_test == test$CARAVAN)

print(paste("Validation Accuracy: ", acc_val_hard))
print(paste("Test Accuracy: ", acc_test_hard))
```











